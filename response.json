{
  "POST Response": [
    {
      "Id": "fea21fde-05e1-40c2-8f3f-d9f1c7346247",
      "Resume Data": {
        "Job Title": "Data Engineer",
        "Matching Percentage": "70",
        "college_name": null,
        "company_names": [],
        "degree": null,
        "designation": null,
        "email": "swapnajakalsait98@gmail.com",
        "experience": 2.5,
        "mobile_number": "8080452179",
        "name": "Swapnaja Kalsait",
        "no_of_pages": null,
        "skills": [
          "Azure Data Factory",
          "Azure Databricks",
          "Azure Gen2 & BLOB Storages",
          "Azure Synapse Analytics",
          "Azure DevOps",
          "Azure Key Vault",
          "Python",
          "ETL & ELT",
          "Snowflake",
          "Oracle SQL",
          "Power BI",
          "Microsoft Fabric",
          "Hadoop",
          "Docker",
          "Kubernetes",
          "Git & GitHub"
        ],
        "certifications": [
          "Fabric Data Engineer Associate"
        ],
        "total_experience":  [
          {
            "role": "Data Engineer Intern",
            "company": "TECHNOMOLD IT Solutions Pvt Ltd",
            "duration": "Jan 2022 - Jun 2022",
            "responsibilities": [
              "Handled data cleansing and preparation tasks using Excel.",
              "Wrote and executed SQL queries for data extraction and transformation.",
              "Performed unit testing to validate data accuracy.",
              "Monitored and debugged data pipelines to ensure reliability and performance."
            ]
          },
          {
            "role": "Azure Data Engineer",
            "company": "TECHNOMOLD IT Solutions Pvt Ltd",
            "duration": "2022 - 2025",
            "responsibilities": [
              "Designed, implemented, and managed data solutions using Azure Data Factory, key vault, Azure Data Lake storage, Databricks, PySpark, and SSMS.",
              "Work closely with data science and data analytics teams. And provide data to them.",
              "Automated data processes, deployments, and monitoring data pipelines.",
              "Monitoring and maintaining daily jobs and daily data loading processes."
            ]
          }
        ]
      },
      "Analysis": {
        "Matching Score": 70,
        "Unmatched Skills": [
          "GCP cloud services",
          "BigQuery",
          "Cloud Functions",
          "MongoDB"
        ],
        "Matched Skills": [
          "SQL",
          "Python",
          "ETL & ELT",
          "Oracle SQL"
        ],
        "Strengths": [
          "Experience with ETL & ELT, Oracle SQL, and Python"
        ],
        "Recommendations": [
          "Consider acquiring certifications in GCP cloud services and BigQuery",
          "Highlight experience with non-relational database management systems"
        ],
        "Required Industrial Experience": "4 years",
        "Required Domain Experience": "0 years",
        "Candidate Industrial Experience": "Candidate has 2.5 years of industrial experience, which falls short of the required 4 years.",
        "Candidate Domain Experience": "0 years"
      }
    }
  ]
}